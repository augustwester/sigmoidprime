<!doctype html> <html lang="en"> <head> <meta charset="utf-8"> <title>Feature Visualization Using DeepDream</title> <meta name="description" content="An introduction to the DeepDream algorithm with interactive visualizations and an associated Python implementation."> <meta name="twitter:card" content="summary_large_image"> <meta name="twitter:creator" content="@augustwester"> <meta name="twitter:title" content="Feature Visualization Using DeepDream"> <meta name="twitter:image" content="https://sigmoidprime.com/assets/posts/6/thumb.png"> <meta name="viewport" content="width=device-width, initial-scale=1, viewport-fit=cover"> <link rel="stylesheet" href="/css/style.css"> <link rel="stylesheet" href="/libs/highlight/styles/github.min.css"> <link rel="stylesheet" href="/libs/katex/katex.min.css"> <link rel="stylesheet" href="/libs/c3/c3.min.css"> <link rel="apple-touch-icon" sizes="180x180" href="/assets/favicons/apple-touch-icon.png"> <link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"> <link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"> <link rel="manifest" href="/assets/favicons/site.webmanifest"> <link rel="mask-icon" href="/assets/favicons/safari-pinned-tab.svg" color="#d249aa"> <link rel="shortcut icon" href="/assets/favicons/favicon.ico"> <meta name="msapplication-TileColor" content="#2b5797"> <meta name="msapplication-config" content="/assets/favicons/browserconfig.xml"> <meta name="theme-color" content="#ffffff"> <link rel="preconnect" href="https://fonts.googleapis.com"> <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin> <link href="https://fonts.googleapis.com/css2?family=Open+Sans&display=swap" rel="stylesheet"> <script src="/libs/highlight/highlight.pack.js"></script> <script src="/libs/katex/katex.min.js"></script> <script src="/libs/katex/contrib/auto-render.js"></script> <script>hljs.initHighlightingOnLoad();</script> </head> <body> <div id="sidebar"> <div id="dismiss-sidebar-icon-container" onclick="toggleSidebar()"> <img src="/assets/icons/cross.svg" id="dismiss-sidebar-icon" alt="Dismiss icon"> </div> <div class="picture"></div> <p class="hi">Hi. I'm <span class="highlight">August</span>.</p> <p class="bio">I'm a <span class="highlight">deep learning</span> enthusiast with broad interests in ML <span class="highlight">research</span> and <span class="highlight">engineering</span>.</p> <p class="bio">I like to understand and explain challenging concepts in the scientific literature, and I enjoy translating abstract theoretical ideas into code. This blog is an excuse for me to do both.</p> <p class="bio">Feel free to reach out if you'd like to say hi üòä</p> <div class="social-media-container"> <div class="social-media-icons"> <a href="https://twitter.com/augustwester"><img src="/assets/icons/twitter.svg" style="width:35px;height:28px;" alt="Twitter icon"></a> <a href="https://github.com/augustwester"><img src="/assets/icons/github.svg" style="width:28px;height:28px;" alt="GitHub icon"></a> <a href="mailto:august.wester@gmail.com"><img src="/assets/icons/email.svg" style="width:28px;height:28px;" alt="Email icon"></a> </div> </div> </div> <div id="overlay"> <div id="content"> <header class="top-header"> <div id="hamburger" onclick="toggleSidebar()"> <div class="sidebar-icon-top"></div> <div class="sidebar-icon-bottom"></div> </div> <div class="inner-header"> <div class="logo-container"> <a href="/"><span class="logo">sigmoid<span class="prime">'</span></span></a> <span class="tagline">a machine learning blog</span> </div> </div> </header> <main style="margin-top:80px;"> <div class="article-container "> <article> <header> <h1 class="post-title">Feature Visualization Using DeepDream</h1> </header> <div class="date-ct"> <div class="date-span"> <p>December 18, 2021</p> </div> <div class="github-span"> <img src="/assets/icons/github.svg"> <a href="https://github.com/augustwester/deepdream" target="_blank">Code available on GitHub</a> </div> <div style="clear:both"></div> </div> <p>Trained neural networks are notoriously opaque. They consist of millions ‚Äî if not billions ‚Äî of parameters, and when they fail, explaining why is not always easy. This has prompted researchers to invent novel techniques that reveal to us why neural networks behave the way they do. One such technique is <a href="https://ai.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html">DeepDream</a>, which besides being a useful research tool is also really fun!</p> <p>Published in 2015 by Google research scientist <a href="https://twitter.com/zzznah">Alex Mordvintsev</a>, DeepDream is a wonderfully simple technique designed to expose the abstract patterns hidden within the interconnections of trained neural networks. Not long after its publication, DeepDream‚Äôs psychedelic imagery quickly infiltrated social media and stoked a public fascination with the strange world of neural nets.</p> <p><img src="/assets/posts/6/seattle.jpeg" width="100%" alt="A psychedelic view of the Seattle skyline" /></p> <p class="subtext">Credit: <a href="https://twitter.com/zzznah/status/1123963384133767169">Alex Mordvintsev</a></p> <p>For the layman, DeepDream is perhaps best explained as a kind of algorithmic <a href="https://en.wikipedia.org/wiki/Pareidolia">pareidolia</a> (the phenomenon of seeing faces or familiar objects in, for instance, a patch of clouds), and more often than not, the algorithm produces bizarre and fascinating images that are sure to catch the attention of anyone who comes across them. However, DeepDream is not <em>just</em> a fun gimmick.</p> <p>While the behavior of trained neural networks are usually opaque to humans, techniques like DeepDream are helping researchers shed a light on their inner workings by allowing the networks to reveal to us what they are seeing. This has given rise to the field known as <a href="https://distill.pub/2018/building-blocks/">interpretability</a>, which aims to make sense of the behavior of trained neural networks.</p> <p>In this post, we will explore how DeepDream works at a high level through interactive visualizations. We will also program an implementation of the algorithm using PyTorch and apply it to a pretrained version of the <a href="https://pytorch.org/hub/pytorch_vision_inception_v3/">Inception-v3 model</a>. This implementation will make it easy for you to create customized ‚Äúdreams‚Äù by running the algorithm on your own images and tweaking its parameters.</p> <h2 id="intuition">Intuition</h2> <p>To understand how DeepDream works at an intuitive level, recall that neural networks rely on <a href="/post/how-to-build-a-neural-network-pt-4">backpropagation</a> and are therefore differentiable end-to-end. DeepDream exploits this property ‚Äî not by minimizing a loss function ‚Äî but by maximizing the output of a hidden layer of one‚Äôs own choosing. Crucially, this optimization is not performed by tweaking the network‚Äôs parameters, but by tweaking the input image itself. This has the interesting effect of the input image slowly morphing into an often surreal version of itself. As shown in the animation below, the modifications are applied iteratively, with each run accentuating the effects more and more.</p> <iframe src="/assets/posts/6/visualization/deep_dream_layer.html" width="66%" height="630px" scrolling="no" style="display:block;border:none;margin:0 auto;"></iframe> <p class="subtext">Select a layer and click play. Darker colors represent higher output values.</p> <p>More formally, assume that $x_n$ is the input image for iteration $n$ of the algorithm, and $y$ is the L2 norm of the corresponding output of an arbitrary hidden layer of a <a href="/post/the-inner-workings-of-convolutional-nets">CNN</a>. To maximize $y$, we obtain $\frac{\partial y}{\partial x_n}$ and update the input image using the update rule $x_{n+1} := x_n + \alpha \frac{\partial y}{\partial x_n}$ where $\alpha$ is some predetermined step size. This process is also known as <strong>gradient ascent</strong>.</p> <p>At a high level, that is all there is to it. However, if we implement this exactly as described, the patterns that appear will occur at a low level of resolution across the image and will often suffer from high-frequency artifacts. While there is nothing inherently wrong with this, we can make use of a few tricks to give our images that extra ‚Äúpop.‚Äù</p> <h2 id="gradient-normalization-octaves-and-jitter">Gradient normalization, octaves, and jitter</h2> <p>To solve the resolution issue, we can start by constructing a <a href="https://en.wikipedia.org/wiki/Pyramid_(image_processing)">Gaussian pyramid</a> from the original image. This is simply a set of increasingly downscaled versions of the image referred to as <a href="https://github.com/google/deepdream/blob/master/dream.ipynb">‚Äòoctaves‚Äô</a>. The octaves are then processed using gradient ascent, from smallest to largest, for a fixed number of iterations. Importantly, since the gradient values are often extremely small, the gradient is normalized before being added to the image.</p> <p>Following the gradient ascent steps, the difference between the untampered octave and its ‚Äòdreamy‚Äô counterpart is obtained as <code class="highlighter-rouge">dream - octave</code>. In the subsequent iteration (this time with a larger octave), this difference is scaled up to match the size of the new octave. These are then added before being sent through the network, and the process is repeated.</p> <iframe src="/assets/posts/6/octaves-jitter/octaves.html" width="100%" height="400px" scrolling="no" style="border:none;"></iframe> <p class="subtext">When an octave has been processed, the changes to the image are extracted, upscaled and applied to the next octave before it too gets processed.</p> <p>Upscaling the changes in this way ensures that the patterns become bigger and more defined, which usually leads to a more intriguing result. You will in other words notice that adjusting the number of octaves is an effective way of managing the size of the patterns in the final image.</p> <p>The final thing we need to take care of is the occurrence of high-frequency artifacts that reduce the ‚Äúsmoothness‚Äù of our images. One way to combat this is by using what the authors of DeepDream call ‚Äújitter,‚Äù which is simply randomized application of the <code class="highlighter-rouge">np.roll</code> function. This means that the image is shifted along the $x$ and $y$ axis while maintaining its original dimensions. The animation below illustrates the combined application of octaves and jitter.</p> <iframe src="/assets/posts/6/octaves-jitter/jitter.html" width="100%" height="400px" scrolling="no" style="border:none;"></iframe> <p>For the best results, jitter should be applied before <em>each</em> step of gradient ascent. I struggled for many hours trying to eliminate the noisy artifcats, with jitter seeming to make almost no difference. The problem turned out to be caused by the fact that I was only applying jitter once <em>per octave</em>.</p> <p>Below is a side-by-side comparison of images optimized using either none, some, or all of the techniques mentioned here.</p> <p><img src="/assets/posts/6/side-by-side.png" width="100%" alt="Four portraits of Vincent van Gogh, each optimized using different configurations of DeepDream" /></p> <p class="subtext">(1) original, (2) only gradient normalization, (3) gradient normalization and octaves, (4) gradient normalization, octaves, and jitter.</p> <p>Each of the images below are the result of optimizing for different layers in the Inception-v3 model (<code class="highlighter-rouge">Mixed_5b</code> through <code class="highlighter-rouge">Mixed_7c</code>). You will notice that the patterns become gradually more complex as the depth of the layer increases. This is a clear demonstration of how each of the network‚Äôs representations are built on top of other more rudimentary ones, going all the way down to the basic colors, edges, and shadows that are encoded in the earliest layers.</p> <iframe src="/assets/posts/6/gallery/gallery.html" width="100%" height="635px" scrolling="no" style="border:none;"></iframe> <p>While optimizing for the output of deeper layers produces gradually more complex patterns, the images also reach a point at which most of the high-level structure appears more noisy than when optimizing for shallower layers. Unfortunately, this makes it difficult for complex patterns such as dogs, cats, cars or people to show up in the final image. I am still not exactly sure what is responsible for this but I would love to know!</p> <h2 id="optimizing-random-noise">Optimizing random noise</h2> <p>Optimizing photographs is fun, but it is not the most useful application of DeepDream from a research perspective. To get the clearest view into a network‚Äôs learned abstractions, one can prevent the input image from biasing the output by starting with an image of random noise. The output thus becomes a more crystallized version of what the layer or filter has learned to recognize.</p> <p>Personally, I find that the most effective (and beautiful) way of optimizing random noise is by progressively zooming into the image while running gradient ascent for a fixed number of steps in each frame. Rather than optimizing for whole layers, optimizing for specific channels usually gives the best results. Below are a few examples.</p> <p><img src="/assets/posts/6/series2.png" width="100%" alt="A variety of colorful patterns" /></p> <p class="subtext">Optimizing for random channels in the Inception-v3 model‚Äôs <code class="highlighter-rouge">Mixed_5</code> and <code class="highlighter-rouge">Mixed_6</code> layers, starting with random noise and using progressive zoom.</p> <p>The provided implementation (see below) makes it easy for you to create images like this, at any resolution you like. Further, it allows you to not only optimize for any layer or channel in the network, but for any combination of layers and channels. The possibilities are endless!</p> <h2 id="implementation">Implementation</h2> <p>To help you run DeepDream on your own images, check out the GitHub repo <a href="https://github.com/augustwester/deep-dream">here</a>.</p> <p>The entrypoint for the algorithm is contained in the file <code class="highlighter-rouge">dream.py</code>. This is also where you can tweak its hyperparameters such as <code class="highlighter-rouge">num_octaves</code>, <code class="highlighter-rouge">steps_per_octave</code>, and <code class="highlighter-rouge">step_size</code>. Perhaps most importantly, the code contains the following dictionary:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">settings</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">"Mixed_5b"</span><span class="p">:</span> <span class="bp">None</span><span class="p">,</span>
    <span class="s">"Mixed_5c"</span><span class="p">:</span> <span class="bp">None</span><span class="p">,</span>
    <span class="s">"Mixed_5d"</span><span class="p">:</span> <span class="p">(</span><span class="mi">42</span><span class="p">,</span> <span class="mi">69</span><span class="p">),</span>
    <span class="s">"Mixed_6a"</span><span class="p">:</span> <span class="bp">None</span><span class="p">,</span>
    <span class="s">"Mixed_6b"</span><span class="p">:</span> <span class="bp">None</span><span class="p">,</span>
    <span class="s">"Mixed_6c"</span><span class="p">:</span> <span class="bp">None</span><span class="p">,</span>
    <span class="s">"Mixed_6d"</span><span class="p">:</span> <span class="bp">None</span><span class="p">,</span>
    <span class="s">"Mixed_6e"</span><span class="p">:</span> <span class="bp">None</span><span class="p">,</span>
    <span class="s">"Mixed_7a"</span><span class="p">:</span> <span class="bp">None</span><span class="p">,</span>
    <span class="s">"Mixed_7b"</span><span class="p">:</span> <span class="bp">None</span><span class="p">,</span>
    <span class="s">"Mixed_7c"</span><span class="p">:</span> <span class="bp">None</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> <p>Changing the dictionary values lets you select which channels and/or layers to optimize. Supplying <code class="highlighter-rouge">"all"</code> as a value optimizes the whole layer while a tuple of ints optimizes the specific channels located at the corresponding indices.</p> <p>To optimize an image, simply load it using <code class="highlighter-rouge">PIL</code> and pass it to the <code class="highlighter-rouge">dream</code> function:</p> <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>img = PIL.Image.load("your_image.jpg")
dream_img = dream(img, num_octaves=3, steps_per_octave=100, settings=settings)
dream_img.save("dream.jpg")
</code></pre></div></div> <p>In order to optimize random noise using progressive zoom, use the functions <code class="highlighter-rouge">random_noise</code> and <code class="highlighter-rouge">zoom_dream</code>:</p> <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>noise = helpers.random_noise(250, 250)
dream_noise = zoom_dream(noise, num_frames=50, steps_per_frame=50, settings=settings)
dream_noise.save("dream_noise.jpg")
</code></pre></div></div> <p>On GitHub, you will find <a href="https://github.com/augustwester/deepdream/blob/main/example.ipynb">a Jupyter notebook</a> which makes it easy to try out both approaches.</p> <h2 id="conclusion">Conclusion</h2> <p>While DeepDream can be a useful tool for researchers, it is also simply a fun and interesting way of breathing new, surreal life into images of all kinds.</p> <p>Personally, I find many of DeepDream‚Äôs images incredibly strange yet oddly familiar. They are reminiscent of <a href="https://en.wikipedia.org/wiki/Phosphene">phosphenes</a> (the phenomenon of seeing light without light actually entering the eye), which is fascinating given that it hints at the fact that the visual abstractions in the brain might be similar to the ones encoded in neural networks.</p> <p>Despite the fact that neural networks are ‚Äútoy models‚Äù of the human brain, there are similarities between the two. Perhaps we will one day be using interpretability techniques to gain insight into the inner workings of the <em>human</em> mind. If that is not an exciting prospect, I don‚Äôt know what is.</p> </article> <br /><br /> <footer> <div class="inner-footer"> <p><b>Questions? Comments? Corrections?</b></p> <br /> <p>Whatever it may be, don't hesitate to let me know. You can get in touch on <a href="https://twitter.com/augustwester" target="_blank">Twitter</a> or via <a href="mailto:august.wester@gmail.com">email</a>.</p> </div> </footer> </div> </main> </div> </div> <script> function toggleSidebar() { let content = document.getElementById("content"); let sidebar = document.getElementById("sidebar"); let overlay = document.getElementById("overlay"); let hamburger = document.getElementById("hamburger"); if (content.classList.contains("translate-right")) { content.classList.remove("translate-right"); sidebar.classList.remove("translate-right"); content.style.pointerEvents = "auto"; overlay.style.cursor = "auto"; document.body.style.overflow = "visible"; overlay.onmouseup = undefined; } else { content.classList.add("translate-right"); content.style.pointerEvents = "none"; overlay.style.cursor = "pointer"; sidebar.classList.add("translate-right"); content.style.pointerEvents = "none"; document.body.style.overflow = "hidden"; overlay.onmouseup = function() { toggleSidebar(); } } } </script> <script type="text/javascript"> var config = [{left:"‚Ç¨‚Ç¨", right:"‚Ç¨‚Ç¨", display:true}, {left: "$", right:"$", display:false}]; renderMathInElement(document.body, {delimiters: config}); </script> <script> (function(i,s,o,g,r,a,m){i["GoogleAnalyticsObject"]=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,"script","https://www.google-analytics.com/analytics.js","ga"); ga("create", "UA-89251189-1", "auto"); ga("send", "pageview"); </script> </body> </html>
