<!doctype html> <html lang="en"> <head> <meta charset="utf-8"> <title>sigmoid prime</title> <meta name="description" content="A blog on machine learning research, in theory and practice."> <link rel="stylesheet" href="/css/style.css"> <meta name="viewport" content="width=device-width, initial-scale=1, viewport-fit=cover"> <link rel="apple-touch-icon" sizes="180x180" href="/assets/favicons/apple-touch-icon.png"> <link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"> <link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"> <link rel="manifest" href="/assets/favicons/site.webmanifest"> <link rel="mask-icon" href="/assets/favicons/safari-pinned-tab.svg" color="#d249aa"> <link rel="shortcut icon" href="/assets/favicons/favicon.ico"> <meta name="msapplication-TileColor" content="#2b5797"> <meta name="msapplication-config" content="/assets/favicons/browserconfig.xml"> <meta name="theme-color" content="#ffffff"> <link rel="preconnect" href="https://fonts.googleapis.com"> <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin> <link href="https://fonts.googleapis.com/css2?family=Open+Sans&display=swap" rel="stylesheet"> </head> <body> <div id="sidebar"> <div id="dismiss-sidebar-icon-container" onclick="toggleSidebar()"> <img src="/assets/icons/cross.svg" id="dismiss-sidebar-icon" alt="Dismiss icon"> </div> <div class="picture"></div> <p class="hi">Hi. I'm <span class="highlight">August</span>.</p> <p class="bio">I recently finished my MSc in computer science at the IT University of <span class="highlight">Copenhagen</span> where I specialized in <span class="highlight">machine learning</span>.</p> <p class="bio">During my studies, I focused primarily on the topics of <span class="highlight">generative models</span>, <span class="highlight">adversarial robustness</span>, and <span class="highlight">causal inference</span>.</p> <p class="bio">I'm driven by the idea of one day creating software with <span class="highlight">creativity</span> and <span class="highlight">personhood</span>.</p> <div class="social-media-container"> <div class="social-media-icons"> <a href="https://twitter.com/augustwester"><img src="/assets/icons/twitter.svg" style="width:35px;height:28px;" alt="Twitter icon"></a> <a href="https://github.com/augustwester"><img src="/assets/icons/github.svg" style="width:28px;height:28px;" alt="GitHub icon"></a> <a href="mailto:august.wester@gmail.com"><img src="/assets/icons/email.svg" style="width:28px;height:28px;" alt="Email icon"></a> </div> </div> </div> <div id="overlay"> <div id="content"> <header class="top-header"> <div id="hamburger" onclick="toggleSidebar()"> <div class="sidebar-icon-top"></div> <div class="sidebar-icon-bottom"></div> </div> <div class="inner-header"> <div class="logo-container"> <a href="/"><span class="logo">sigmoid<span class="prime">'</span></span></a> <span class="tagline">a machine learning blog</span> </div> </div> </header> <main> <div class="front-page-article-container"> <article> <a href="/post/transformer-xl/"> <div class="thumbnail-container"> <img class="thumbnail" src="/assets/posts/transformer-xl/thumb.png" alt="A left-shifted matrix"> </div> </a> <a href="/post/transformer-xl/"> <h1> Transformer-XL: A Memory-Augmented Transformer </h1> </a> <p>In this post, we will implement a lightweight version of the Transformer-XL model. Proposed by Dai et al. in 2019, Transformer-XL introduced two innovations that, when combined, enable the attention mechanism to have a wider “field of view” and result in significant performance improvements on autoregressive evaluation.</p> <div style="clear:both"></div> <p> <a href="/post/transformer-xl/" class="read-more-link">Read more <svg width="13" style="margin-left:5px;" height="11" viewBox="0 0 13 11"> <path d="M7.556 0L6.42 1.137 9.91 4.63H0v1.626h9.912L6.42 9.75l1.136 1.137L13 5.444" fill="rgb(210,73, 170)"></path> </svg> </a> </p> </article> </div> <div class="separating-line"></div> <div class="front-page-article-container"> <article> <a href="/post/gflownets/"> <div class="thumbnail-container"> <img class="thumbnail" src="/assets/posts/gflownets/thumb.png" alt="Transitions between states in a GFlowNet"> </div> </a> <a href="/post/gflownets/"> <h1> Proportional Reward Sampling With GFlowNets </h1> </a> <p>Imagine a chemist in search of a novel drug that will bind to a specific protein in the human body. The chemist is faced with two problems: 1) The space of possible drugs is enormous and 2) the cost of synthesizing a large variety of candidate drugs and evaluating their efficacy is prohibitively expensive and time-consuming.</p> <div style="clear:both"></div> <p> <a href="/post/gflownets/" class="read-more-link">Read more <svg width="13" style="margin-left:5px;" height="11" viewBox="0 0 13 11"> <path d="M7.556 0L6.42 1.137 9.91 4.63H0v1.626h9.912L6.42 9.75l1.136 1.137L13 5.444" fill="rgb(210,73, 170)"></path> </svg> </a> </p> </article> </div> <div class="separating-line"></div> <div class="front-page-article-container"> <article> <a href="/post/deepdream/"> <div class="thumbnail-container"> <img class="thumbnail" src="/assets/posts/6/thumb.png" alt="Layer activations in a neural network"> </div> </a> <a href="/post/deepdream/"> <h1> Feature Visualization Using DeepDream </h1> </a> <p>Trained neural networks are notoriously opaque. They consist of millions — if not billions — of parameters, and when they fail, explaining why is not always easy. This has prompted researchers to invent novel techniques that reveal to us why neural networks behave the way they do. One such technique is <a href="https://ai.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html">DeepDream</a>, which besides being a useful research tool is also really fun!</p> <div style="clear:both"></div> <p> <a href="/post/deepdream/" class="read-more-link">Read more <svg width="13" style="margin-left:5px;" height="11" viewBox="0 0 13 11"> <path d="M7.556 0L6.42 1.137 9.91 4.63H0v1.626h9.912L6.42 9.75l1.136 1.137L13 5.444" fill="rgb(210,73, 170)"></path> </svg> </a> </p> </article> </div> <div class="separating-line"></div> <div class="front-page-article-container"> <article> <a href="/post/the-inner-workings-of-convolutional-nets/"> <div class="thumbnail-container"> <img class="thumbnail" src="/assets/posts/5/thumb.png" alt="Convolution operation on an image"> </div> </a> <a href="/post/the-inner-workings-of-convolutional-nets/"> <h1> The Inner Workings of Convolutional Nets </h1> </a> <p>Of all the stunning advancements in deep learning made in the last 10 years, the progress in the field of computer vision is perhaps the most striking. At the heart of this progress is a model known as a convolutional neural network – or “CNN” for short – which resembles the structure of the brain’s visual cortex and has become a staple of almost all computer vision systems today.</p> <div style="clear:both"></div> <p> <a href="/post/the-inner-workings-of-convolutional-nets/" class="read-more-link">Read more <svg width="13" style="margin-left:5px;" height="11" viewBox="0 0 13 11"> <path d="M7.556 0L6.42 1.137 9.91 4.63H0v1.626h9.912L6.42 9.75l1.136 1.137L13 5.444" fill="rgb(210,73, 170)"></path> </svg> </a> </p> </article> </div> <div class="separating-line"></div> <div class="front-page-article-container"> <article> <a href="/post/how-to-build-a-neural-network-pt-4/"> <div class="thumbnail-container"> <img class="thumbnail" src="/assets/posts/4/thumb.png" alt="A function in 3D with peaks and valleys"> </div> </a> <a href="/post/how-to-build-a-neural-network-pt-4/"> <h1> How to Build (and Understand) a Neural Network Pt. 4: Backpropagation </h1> </a> <p>In this final post of the series, we will see how to apply <strong>backpropagation</strong> to the neural net we built in the last chapter. This will allow our network to incrementally improve itself as it gets exposed to new data, which will ultimately enable it to classify the MNIST test set with close to 95% accuracy.</p> <div style="clear:both"></div> <p> <a href="/post/how-to-build-a-neural-network-pt-4/" class="read-more-link">Read more <svg width="13" style="margin-left:5px;" height="11" viewBox="0 0 13 11"> <path d="M7.556 0L6.42 1.137 9.91 4.63H0v1.626h9.912L6.42 9.75l1.136 1.137L13 5.444" fill="rgb(210,73, 170)"></path> </svg> </a> </p> </article> </div> <div class="separating-line"></div> <div class="front-page-article-container"> <article> <a href="/post/how-to-build-a-neural-network-pt-3/"> <div class="thumbnail-container"> <img class="thumbnail" src="/assets/posts/3/thumb.png" alt="A transformed coordinate system"> </div> </a> <a href="/post/how-to-build-a-neural-network-pt-3/"> <h1> How to Build (and Understand) a Neural Network Pt. 3: The Forward Pass </h1> </a> <p>By now, we have covered a whole lot of material. We have talked about decision boundaries, loss functions, and gradient descent, and we have built our own linear models using the perceptron and logistic regression algorithms. In this penultimate post of the series, we will analyze the first half of a neural network — the <strong>forward pass</strong> — and we will use linear algebra to explore a visual interpretation of what happens to our data as it flows through a neural net.</p> <div style="clear:both"></div> <p> <a href="/post/how-to-build-a-neural-network-pt-3/" class="read-more-link">Read more <svg width="13" style="margin-left:5px;" height="11" viewBox="0 0 13 11"> <path d="M7.556 0L6.42 1.137 9.91 4.63H0v1.626h9.912L6.42 9.75l1.136 1.137L13 5.444" fill="rgb(210,73, 170)"></path> </svg> </a> </p> </article> </div> <div class="separating-line"></div> <div class="front-page-article-container"> <article> <a href="/post/how-to-build-a-neural-network-pt-2/"> <div class="thumbnail-container"> <img class="thumbnail" src="/assets/posts/2/thumb.png" alt="A gradient of confidence on either side of a decision boundary"> </div> </a> <a href="/post/how-to-build-a-neural-network-pt-2/"> <h1> How to Build (and Understand) a Neural Network Pt. 2: Logistic Regression </h1> </a> <p>In the <a href="http://sigmoidprime.com/post/how-to-build-a-neural-network-pt-1/">previous post</a>, we saw how the perceptron algorithm automatically discovered how to distinguish data points belonging to two different classes. This time, we will explore the ideas behind another algorithm — <strong>logistic regression</strong> — to see how and why it plays a central role in many neural network architectures. We will also demonstrate how it can be used to model slightly more complex and interesting data than the Iris dataset.</p> <div style="clear:both"></div> <p> <a href="/post/how-to-build-a-neural-network-pt-2/" class="read-more-link">Read more <svg width="13" style="margin-left:5px;" height="11" viewBox="0 0 13 11"> <path d="M7.556 0L6.42 1.137 9.91 4.63H0v1.626h9.912L6.42 9.75l1.136 1.137L13 5.444" fill="rgb(210,73, 170)"></path> </svg> </a> </p> </article> </div> <div class="separating-line"></div> <div class="front-page-article-container"> <article> <a href="/post/how-to-build-a-neural-network-pt-1/"> <div class="thumbnail-container"> <img class="thumbnail" src="/assets/posts/1/thumb.png" alt="A point embedded in 3D space"> </div> </a> <a href="/post/how-to-build-a-neural-network-pt-1/"> <h1> How to Build (and Understand) a Neural Network Pt. 1: The Perceptron </h1> </a> <p>Building a neural network is fairly easy. It doesn’t require you to know any obscure programming language, and you can build a working model with surprisingly few lines of code. To understand how it works however — to <em>really</em> understand it — takes mathematical insight more than anything else. While this may sound lofty, anyone with a firm grasp of high school level math is equipped to take on the task.</p> <div style="clear:both"></div> <p> <a href="/post/how-to-build-a-neural-network-pt-1/" class="read-more-link">Read more <svg width="13" style="margin-left:5px;" height="11" viewBox="0 0 13 11"> <path d="M7.556 0L6.42 1.137 9.91 4.63H0v1.626h9.912L6.42 9.75l1.136 1.137L13 5.444" fill="rgb(210,73, 170)"></path> </svg> </a> </p> </article> </div> <div class="separating-line"></div> </main> </div> </div> <script> function toggleSidebar() { let content = document.getElementById("content"); let sidebar = document.getElementById("sidebar"); let overlay = document.getElementById("overlay"); let hamburger = document.getElementById("hamburger"); if (content.classList.contains("translate-right")) { content.classList.remove("translate-right"); sidebar.classList.remove("translate-right"); content.style.pointerEvents = "auto"; overlay.style.cursor = "auto"; document.body.style.overflow = "visible"; overlay.onmouseup = undefined; } else { content.classList.add("translate-right"); content.style.pointerEvents = "none"; overlay.style.cursor = "pointer"; sidebar.classList.add("translate-right"); content.style.pointerEvents = "none"; document.body.style.overflow = "hidden"; overlay.onmouseup = function() { toggleSidebar(); } } } </script> <script> (function(i,s,o,g,r,a,m){i["GoogleAnalyticsObject"]=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,"script","https://www.google-analytics.com/analytics.js","ga"); ga("create", "UA-89251189-1", "auto"); ga("send", "pageview"); </script> </div> </body> </html>
